{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up\n",
        "\n",
        "Choose the MTG set and draft format (Premier or Traditional) to analyze"
      ],
      "metadata": {
        "id": "bURIiNZpoOwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the MTG set. This is the 3 letter code for a set\n",
        "EXPANSION = \"LCI\"\n",
        "\n",
        "FORMAT_PREMIER_DRAFT = \"PremierDraft\"\n",
        "FORMAT_TRADITIONAL_DRAFT = \"TradDraft\"\n",
        "\n",
        "# Choose the format to analyze\n",
        "FORMAT = FORMAT_PREMIER_DRAFT"
      ],
      "metadata": {
        "id": "pOlKvSc7p9fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the draft dataset\n",
        "\n",
        "Download the datasets. The datasets are from the [17 Lands Public Data Sets](https://www.17lands.com/public_datasets)."
      ],
      "metadata": {
        "id": "UFKSSYrABRPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GAME_DATA_FILE = f\"game_data_public.{EXPANSION}.{FORMAT}.csv.gz\"\n",
        "GAME_DATA_REMOTE_URL = f\"https://17lands-public.s3.amazonaws.com/analysis_data/game_data/{GAME_DATA_FILE}\"\n",
        "DRAFT_DATA_FILE = f\"draft_data_public.{EXPANSION}.{FORMAT}.csv.gz\"\n",
        "DRAFT_DATA_REMOTE_URL = f\"https://17lands-public.s3.amazonaws.com/analysis_data/draft_data/{DRAFT_DATA_FILE}\"\n",
        "\n",
        "!wget {GAME_DATA_REMOTE_URL}\n",
        "!wget {DRAFT_DATA_REMOTE_URL}\n",
        "!wget https://17lands-public.s3.amazonaws.com/analysis_data/cards/cards.csv"
      ],
      "metadata": {
        "id": "43fMhsrunfIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Pandas and Set Useful Options\n",
        "\n",
        "Pandas is what we'll use to analyze the data. For more info on Pandas, see the [docs](https://pandas.pydata.org/docs/user_guide/10min.html)."
      ],
      "metadata": {
        "id": "CtQPSk8Mn1V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_columns', 1600)"
      ],
      "metadata": {
        "id": "9NJusHEvH1xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore The Data Set\n",
        "\n",
        "There are 3 key datasets to explore. The main datasets are the draft and game data sets for an MTG set. Another dataset that can often be useful is the list of all cards on arena."
      ],
      "metadata": {
        "id": "tbROPQjKHqCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Game Data\n",
        "df = next(pd.read_csv(GAME_DATA_FILE, chunksize=100))\n",
        "df.head(25)"
      ],
      "metadata": {
        "id": "vIg5P6VaHvF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draft Data\n",
        "df = next(pd.read_csv(DRAFT_DATA_FILE, chunksize=100))\n",
        "df.head(55)"
      ],
      "metadata": {
        "id": "7hSoUD0BH2HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cards_table = pd.read_csv(\"cards.csv\")\n",
        "set_cards = cards_table[cards_table[\"expansion\"] == EXPANSION]\n",
        "set_cards.head(25)"
      ],
      "metadata": {
        "id": "CxhCYVpEnTRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze Data"
      ],
      "metadata": {
        "id": "sc2JAtmUrtip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Helper Functions\n",
        "\n",
        "Some useful functions for common ways to use the data sets"
      ],
      "metadata": {
        "id": "vl4xFbz7qPuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_drafts():\n",
        "  \"\"\"\n",
        "  Returns a table with one row per draft\n",
        "  \"\"\"\n",
        "  cols = [\"expansion\", \"event_type\", \"draft_id\", \"draft_time\", \"rank\", \"event_match_wins\", \"event_match_losses\"]\n",
        "  chunks = list()\n",
        "  for draft_data in pd.read_csv(\n",
        "      DRAFT_DATA_FILE,\n",
        "      chunksize=100000,\n",
        "      usecols=cols\n",
        "      ):\n",
        "    draft_data_no_dups = draft_data.drop_duplicates(subset=[\"draft_id\"])\n",
        "    chunks.append(draft_data_no_dups)\n",
        "\n",
        "  all_drafts = pd.concat(chunks)\n",
        "\n",
        "  # Remove duplicates in case of drafts that show up in multiple chunks\n",
        "  all_drafts = all_drafts.drop_duplicates(subset=[\"draft_id\"], keep=\"last\")\n",
        "  return all_drafts"
      ],
      "metadata": {
        "id": "DNTOjw4gqPH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_game_data_cols():\n",
        "  \"\"\"\n",
        "  Returns the columns in the game data file that includes metadata and which cards were in the deck. Filters out other columns to reduce size of the dataset\n",
        "  \"\"\"\n",
        "  df = next(pd.read_csv(GAME_DATA_FILE, chunksize=100))\n",
        "  col_names = list(df)\n",
        "  gd_card_cols = [x for x in col_names if x.startswith(\"deck_\")]\n",
        "\n",
        "  gd_base_cols = ['draft_id', 'main_colors', 'splash_colors', 'user_n_games_bucket', 'user_game_win_rate_bucket', 'won']\n",
        "  gd_all_cols = gd_base_cols + gd_card_cols\n",
        "  return gd_all_cols\n",
        "\n",
        "def get_all_decks(summerize):\n",
        "  \"\"\"\n",
        "  summerize: if True, only return the last deck for each draft\n",
        "  Returns all decks available in the format.\n",
        "  \"\"\"\n",
        "  gd_all_cols = get_game_data_cols()\n",
        "  chunks = list()\n",
        "  for game_data in pd.read_csv(\n",
        "      GAME_DATA_FILE,\n",
        "      chunksize=100000,\n",
        "      usecols=gd_all_cols\n",
        "      ):\n",
        "    if summerize:\n",
        "      # Drop duplciates on draft id, keep the last\n",
        "      game_data_no_dups = game_data.drop_duplicates(subset=[\"draft_id\"], keep=\"last\")\n",
        "      chunks.append(game_data_no_dups)\n",
        "    else:\n",
        "      chunks.append(game_data)\n",
        "\n",
        "  all_games = pd.concat(chunks)\n",
        "  if summerize:\n",
        "    all_games = all_games.drop_duplicates(subset=[\"draft_id\"], keep=\"last\")\n",
        "  all_games_names_fixed = all_games.rename(columns=lambda x: x[5:] if x.startswith(\"deck_\") else x)\n",
        "  return all_games_names_fixed"
      ],
      "metadata": {
        "id": "X5HMOLnXtjyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Caves Decks\n",
        "\n",
        "Let's enrich the dataset with counts of relevant cave & cave payoff cards"
      ],
      "metadata": {
        "id": "obXs1RDUsYsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_caves = [\"Hidden Cataract\", \"Hidden Courtyard\", \"Hidden Necropolis\", \"Hidden Nursery\", \"Hidden Volcano\"]\n",
        "flip_caves = [\"Brass's Tunnel-Grinder\", \"Dowsing Device\", \"Grasping Shadows\", \"Tarrian's Journal\", \"Twists and Turns\"]\n",
        "fixing_caves = [\"Captivating Cave\", \"Forgotten Monument\", \"Promising Vein\", \"Sunken Citadel\"]\n",
        "non_flip_cave_cards = [\"Captivating Cave\", \"Cavernous Maw\", \"Echoing Deeps\", \"Forgotten Monument\", \"Hidden Cataract\", \"Hidden Courtyard\", \"Hidden Necropolis\", \"Hidden Nursery\", \"Hidden Volcano\", \"Pit of Offerings\", \"Promising Vein\", \"Sunken Citadel\", \"Volatile Fault\"]\n",
        "\n",
        "cave_payoffs = [\"Bat Colony\", \"Calamitous Cave-In\", \"Gargantuan Leech\", \"Sinuous Benthisaur\"]\n",
        "cave_related = [\"Compass Gnome\", \"Cosmium Confluence\", \"Glimpse the Core\", \"Kaslem's Stonetree\", \"Scampering Surveyor\", \"Spelunking\"]\n",
        "\n",
        "def add_cave_data(decks):\n",
        "  caves_decks = decks.copy()\n",
        "\n",
        "  caves_decks[\"hidden_caves_count\"] = caves_decks[hidden_caves].sum(axis=1)\n",
        "  caves_decks[\"flip_caves\"] = caves_decks[flip_caves].sum(axis=1)\n",
        "  caves_decks[\"fixing_caves\"] = caves_decks[fixing_caves].sum(axis=1)\n",
        "  caves_decks[\"non_flip_cave_cards\"] = caves_decks[non_flip_cave_cards].sum(axis=1)\n",
        "  caves_decks[\"non_flip_cave_cards\"] = caves_decks.apply(lambda x: min(x[\"non_flip_cave_cards\"], 11), axis=1)\n",
        "\n",
        "  caves_decks[\"cave_payoffs\"] = caves_decks[cave_payoffs].sum(axis=1)\n",
        "  caves_decks[\"cave_payoffs\"] = caves_decks.apply(lambda x: min(x[\"cave_payoffs\"], 7), axis=1)\n",
        "  caves_decks[\"cave_related\"] = caves_decks[cave_related].sum(axis=1)\n",
        "\n",
        "  return caves_decks"
      ],
      "metadata": {
        "id": "VgFvnrudsbgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This step may take a few minutes\n",
        "USE_WIN_PERCENT = True\n",
        "\n",
        "if USE_WIN_PERCENT:\n",
        "  all_decks = get_all_decks(summerize = False)\n",
        "else:\n",
        "  all_decks = get_all_decks(summerize = True)\n",
        "\n",
        "draft_metadata = get_all_drafts()\n",
        "all_decks.head(25)"
      ],
      "metadata": {
        "id": "xf7FIYQxuspj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cave_aggregations(use_win_percentage, decks, draft_metadata):\n",
        "  win_col_name = \"won_int\" if use_win_percentage else \"event_match_wins\"\n",
        "  df = decks.copy()\n",
        "\n",
        "  if use_win_percentage:\n",
        "    df[\"won_int\"] = df[\"won\"].astype(int)\n",
        "  else:\n",
        "    df = pd.merge(decks, draft_metadata, on=[\"draft_id\"])\n",
        "\n",
        "  df = df.filter(items=[\"hidden_caves_count\", \"flip_caves\", \"fixing_caves\", \"non_flip_cave_cards\", \"cave_payoffs\", \"cave_related\", win_col_name])\n",
        "  df = df.groupby([\"non_flip_cave_cards\", \"cave_payoffs\"]).agg([\"mean\", \"size\"])\n",
        "\n",
        "  df = df[win_col_name].copy()\n",
        "  df = df.reset_index()\n",
        "  return df"
      ],
      "metadata": {
        "id": "eRtkNQp--n1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_decks_with_cave_data = add_cave_data(all_decks)\n",
        "cave_stats = get_cave_aggregations(USE_WIN_PERCENT, all_decks_with_cave_data, draft_metadata)\n",
        "cave_stats.head(25)"
      ],
      "metadata": {
        "id": "akByte9SLQTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graphs\n",
        "\n",
        "Now that the data has been enriched, we can graph the data with a heatmap. Note, we only show boxes that have enough data points to be relevant"
      ],
      "metadata": {
        "id": "aMS30NpNOlEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "G75hJ0WJPM35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_cave_data(cave_decks, max_cave_payoffs, max_caves, use_win_percent):\n",
        "  hm = np.zeros((max_cave_payoffs, max_caves))\n",
        "  hm.fill(None)\n",
        "  size_threshold = 50 if use_win_percent else 10\n",
        "\n",
        "  for index, row in cave_decks.iterrows():\n",
        "    non_flip_cave_cards = int(row[\"non_flip_cave_cards\"])\n",
        "    cave_payoffs = int(row[\"cave_payoffs\"])\n",
        "    mean = row[\"mean\"]\n",
        "    if row[\"size\"] >= size_threshold:\n",
        "      hm[cave_payoffs, non_flip_cave_cards] = mean\n",
        "\n",
        "  hm_df = DataFrame(hm, index=range(max_cave_payoffs), columns=range(max_caves))\n",
        "  hm_df = hm_df[::-1]\n",
        "\n",
        "  plt.figure(figsize=(16,9))\n",
        "  sns.set(style=\"ticks\")\n",
        "  plt.style.use(\"dark_background\")\n",
        "\n",
        "  vmin = .45 if use_win_percent else 2\n",
        "  vmax = .59 if use_win_percent else 3\n",
        "  center = .52 if use_win_percent else 2.5\n",
        "\n",
        "  ax = sns.heatmap(\n",
        "      hm_df,\n",
        "      annot=True,\n",
        "      cmap=\"RdYlGn\",\n",
        "      robust=True,\n",
        "      fmt=\".2f\",\n",
        "      linewidth=.25,\n",
        "      linecolor=\"black\",\n",
        "      center=center,\n",
        "      vmin=vmin,\n",
        "      vmax=vmax,\n",
        "      cbar=False\n",
        "      )\n",
        "  ax.set(xlabel=\"Caves in Deck\", ylabel=\"Cave Payoffs in Deck\")\n",
        "  ax.xaxis.labelpad = 20\n",
        "  ax.yaxis.labelpad = 20\n",
        "  return ax"
      ],
      "metadata": {
        "id": "HfeWJO1EEZNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = graph_cave_data(cave_stats, 8, 12, USE_WIN_PERCENT)"
      ],
      "metadata": {
        "id": "16mNeiiCQF0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Stats\n",
        "\n",
        "Other stats I was looking at during development. These may need tweaking, as they were originally built without using win percentage."
      ],
      "metadata": {
        "id": "lfvXJzKZRKcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_cave_decks = all_decks_with_cave_data[(all_decks_with_cave_data[\"non_flip_cave_cards\"] >= 8) & (all_decks_with_cave_data[\"cave_payoffs\"] >= 4)]\n",
        "print(len(optimal_cave_decks))\n",
        "# optimal_cave_decks.head(25)\n",
        "\n",
        "\n",
        "color_group_breakdown = optimal_cave_decks.copy()\n",
        "color_group_breakdown = color_group_breakdown.filter(items=[\"main_colors\"])\n",
        "cgb_group = color_group_breakdown.value_counts()\n",
        "print(cgb_group)\n",
        "\n",
        "cgb = optimal_cave_decks.copy()\n",
        "cgb = cgb.filter(items=[\"main_colors\", \"splash_colors\"])\n",
        "cgb[\"all_colors\"] = cgb['main_colors'].str.cat(cgb[['splash_colors']], na_rep='')\n",
        "for c in \"WUBRG\":\n",
        "  print(f\"Checking color: {c}\")\n",
        "  cgb[c] = cgb[\"all_colors\"].str.contains(c)\n",
        "  print(cgb[c].value_counts(normalize=True).mul(100).astype(str)+'%')\n",
        "\n",
        "cgb[\"num_colors\"] = cgb[\"all_colors\"].str.len()\n",
        "print(cgb[\"num_colors\"].value_counts(normalize=True))\n",
        "print(cgb)\n",
        "\n",
        "\n",
        "cave_cats = [hidden_caves, flip_caves, fixing_caves, non_flip_cave_cards, cave_payoffs, cave_related]\n",
        "for cc in cave_cats:\n",
        "  cave_copy = optimal_cave_decks.copy()\n",
        "  cc_stats = cave_copy.filter(items=cc).mean().sort_values(ascending=False)\n",
        "  print(\"\\n\\n\")\n",
        "  print(cc_stats)"
      ],
      "metadata": {
        "id": "ht4MrNumJmQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}